{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install langchain langchain_ollama pandas tqdm\n",
    "\n",
    "\n",
    "# Clone the repository\n",
    "!git clone https://github.com/ostinsolo/Audio-Engineer-Sound-Design-LLM.git\n",
    "%cd Audio-Engineer-Sound-Design-LLM/ai_gen\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Load the Ableton data\n",
    "from ableton_data import *\n",
    "from utterance_actions_template import action_order_templates, utterance_templates\n",
    "\n",
    "# Load the Ollama LLM\n",
    "llm = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"ableton_data\"],\n",
    "    template=\"\"\"\n",
    "Generate a unique utterance for an Ableton Live task and its corresponding action order. Use the provided Ableton data to ensure relevance and accuracy.\n",
    "\n",
    "Ableton Data:\n",
    "{ableton_data}\n",
    "\n",
    "Format the output as follows:\n",
    "Utterance: [insert utterance here]\n",
    "Action Order: [\"step 1\", \"step 2\", ...]\n",
    "\n",
    "Rules:\n",
    "1. Track-related actions always start with \"track {track_number}\" unless it's a global action.\n",
    "2. Device-related actions always start with \"search device\" followed by the device name.\n",
    "3. For instruments, the order is: \"search device\", \"{instrument}\", \"{device_type}\", then the action.\n",
    "4. Audio effects are treated separately from instruments.\n",
    "5. Control actions include one of the speed modifiers, followed by a value between 0 and 100.\n",
    "6. When creating a track, don't mention a track number (it doesn't exist yet).\n",
    "7. Use one of the common actions in the utterance.\n",
    "8. You can use or adapt one of the utterance templates, or create a new utterance based on the provided data.\n",
    "\n",
    "Now generate a new, unique utterance and action order:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "def extract_utterance_and_action(response):\n",
    "    utterance_match = re.search(r'Utterance: (.+)', response)\n",
    "    action_order_match = re.search(r'Action Order: (\\[.+\\])', response)\n",
    "    \n",
    "    utterance = utterance_match.group(1) if utterance_match else None\n",
    "    action_order = eval(action_order_match.group(1)) if action_order_match else None\n",
    "    \n",
    "    return utterance, action_order\n",
    "\n",
    "def generate_utterance_and_action():\n",
    "    # Randomly select elements from the Ableton data to encourage variety\n",
    "    audio_effect = random.choice(audio_effects)\n",
    "    instrument = random.choice(instruments)\n",
    "    device_type = random.choice(device_types[instrument])\n",
    "    action_category = random.choice(list(actions.keys()))\n",
    "    action = random.choice(actions[action_category])\n",
    "    template = random.choice(utterance_templates)\n",
    "    speed_modifier = random.choice(sum(speed_modifiers.values(), []))\n",
    "    \n",
    "    # Create a simplified version of the Ableton data to pass to the AI\n",
    "    simplified_data = {\n",
    "        'selected_audio_effect': audio_effect,\n",
    "        'selected_instrument': instrument,\n",
    "        'selected_device_type': device_type,\n",
    "        'selected_action': action,\n",
    "        'selected_template': template,\n",
    "        'selected_speed_modifier': speed_modifier,\n",
    "        'action_order_templates': action_order_templates\n",
    "    }\n",
    "    \n",
    "    prompt = prompt_template.format(ableton_data=str(simplified_data))\n",
    "    output = llm(prompt)\n",
    "    return extract_utterance_and_action(output)\n",
    "\n",
    "def generate_action_order(utterance, template):\n",
    "    action_order = template.copy()\n",
    "    \n",
    "    # Handle track creation separately\n",
    "    if \"create track\" in utterance or \"new track\" in utterance:\n",
    "        return handle_track_creation(utterance, action_order)\n",
    "    \n",
    "    # If a device is mentioned, ensure it starts with \"search device\"\n",
    "    if any(device in utterance for device in [\"{audio_effect}\", \"{instrument}\", \"{device_type}\"]):\n",
    "        if action_order[0] != \"search device\":\n",
    "            action_order.insert(0, \"search device\")\n",
    "    \n",
    "    # For Control actions, generate a random value\n",
    "    if \"Control\" in utterance:\n",
    "        value_index = action_order.index(\"{value}\")\n",
    "        action_order[value_index] = str(random.randint(0, 100))\n",
    "    \n",
    "    # Ensure track-related actions start with the track number\n",
    "    if \"track\" in utterance and not action_order[0].startswith((\"track\", \"create track\")):\n",
    "        track_number = extract_track_number(utterance)\n",
    "        action_order.insert(0, f\"track {track_number}\")\n",
    "    \n",
    "    return action_order\n",
    "\n",
    "def handle_track_creation(utterance, action_order):\n",
    "    # For track creation, we don't need to add a track number\n",
    "    if \"create track\" not in action_order:\n",
    "        action_order.insert(0, \"create track\")\n",
    "    \n",
    "    # Extract track type and instrument if present\n",
    "    track_type = extract_track_type(utterance)\n",
    "    instrument = extract_instrument(utterance)\n",
    "    \n",
    "    if track_type:\n",
    "        action_order.insert(1, track_type)\n",
    "    if instrument:\n",
    "        action_order.append(f\"add {instrument}\")\n",
    "    \n",
    "    return action_order\n",
    "\n",
    "def extract_track_numbers(utterance):\n",
    "    matches = re.findall(r'track (\\d+)', utterance)\n",
    "    if not matches:\n",
    "        return [\"1\"]  # Default to track 1 if no numbers found\n",
    "    return matches\n",
    "\n",
    "def extract_track_type(utterance):\n",
    "    track_types = [\"audio\", \"MIDI\", \"return\", \"master\", \"group\"]\n",
    "    for track_type in track_types:\n",
    "        if track_type.lower() in utterance.lower():\n",
    "            return track_type\n",
    "    return \"audio\"  # Default to audio if no type specified\n",
    "\n",
    "def extract_instrument(utterance):\n",
    "    # This function would contain logic to extract the instrument name from the utterance\n",
    "    # For simplicity, let's assume it just checks for the presence of \"instrument\" keyword\n",
    "    if \"instrument\" in utterance:\n",
    "        return \"{instrument}\"\n",
    "    return None\n",
    "\n",
    "# Generate the data\n",
    "num_generations = 100  # You can adjust this number\n",
    "generated_data = []\n",
    "\n",
    "for _ in tqdm(range(num_generations), desc=\"Generating utterances and actions\"):\n",
    "    utterance, action_order = generate_utterance_and_action()\n",
    "    if utterance and action_order:\n",
    "        generated_data.append({\"Utterance\": utterance, \"Action_Order\": action_order})\n",
    "\n",
    "print(f\"Generated {len(generated_data)} utterances and action orders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Enable tqdm for pandas operations\n",
    "tqdm.pandas()\n",
    "\n",
    "def create_csv_from_ai_output(input_data, output_file):\n",
    "    # Convert the input data to a pandas DataFrame\n",
    "    df = pd.DataFrame(input_data)\n",
    "    \n",
    "    # Convert the Action_Order list to a comma-separated string\n",
    "    df['Action_Order'] = df['Action_Order'].progress_apply(lambda x: ', '.join(x))\n",
    "    \n",
    "    # Write the DataFrame to a CSV file\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"CSV file '{output_file}' has been created successfully.\")\n",
    "\n",
    "# Create the CSV file\n",
    "output_file = 'ableton_utterances_and_actions.csv'\n",
    "create_csv_from_ai_output(generated_data, output_file)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
