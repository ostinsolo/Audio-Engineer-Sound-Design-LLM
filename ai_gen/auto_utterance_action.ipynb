{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Ensure we're in the correct directory\n",
    "if not os.path.exists('ableton_data.py'):\n",
    "    script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    os.chdir(script_dir)\n",
    "\n",
    "# Add the current directory to Python's path\n",
    "sys.path.append('.')\n",
    "\n",
    "# Load the Ableton data\n",
    "from ableton_data import *\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load the Ollama LLM\n",
    "llm = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"placeholders\", \"examples\"],\n",
    "    template=\"\"\"\n",
    "Generate a unique utterance for an Ableton Live task and its corresponding action order based on the provided placeholders. Use the same placeholder values in both the utterance and the action order.\n",
    "\n",
    "Examples:\n",
    "\n",
    "{examples}\n",
    "\n",
    "Placeholders:\n",
    "{placeholders}\n",
    "\n",
    "Format the output as follows:\n",
    "Utterance: [insert utterance here]\n",
    "Action Order: [\"step 1\", \"step 2\", ...]\n",
    "\n",
    "Now generate the utterance and action order.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "def format_placeholders(placeholders):\n",
    "    return '\\n'.join(f\"- {key}: \\\"{value}\\\"\" for key, value in placeholders.items())\n",
    "\n",
    "examples_list = [\n",
    "    {\n",
    "        'placeholders': {\n",
    "            'track_creation_action': 'add',\n",
    "            'track_type': 'MIDI'\n",
    "        },\n",
    "        'utterance': 'Add a MIDI track',\n",
    "        'action_order': '[\"add\", \"MIDI\"]'\n",
    "    },\n",
    "    {\n",
    "        'placeholders': {\n",
    "            'track_number': 2,\n",
    "            'track_action': 'mute'\n",
    "        },\n",
    "        'utterance': 'Mute track 2',\n",
    "        'action_order': '[\"track 2\", \"mute\"]'\n",
    "    },\n",
    "    # Add more examples as needed\n",
    "]\n",
    "\n",
    "def format_examples(examples):\n",
    "    formatted_examples = \"\"\n",
    "    for example in examples:\n",
    "        placeholders_str = '\\n'.join(f\"- {key}: \\\"{value}\\\"\" for key, value in example['placeholders'].items())\n",
    "        formatted_examples += f\"\"\"\n",
    "Example:\n",
    "Placeholders:\n",
    "{placeholders_str}\n",
    "\n",
    "Utterance: \"{example['utterance']}\"\n",
    "Action Order: {example['action_order']}\n",
    "\"\"\"\n",
    "    return formatted_examples\n",
    "\n",
    "def extract_utterance_and_action(response):\n",
    "    utterance_match = re.search(r'Utterance:\\s*(.+)', response)\n",
    "    action_order_match = re.search(r'Action Order:\\s*(\\[[^\\]]*\\])', response)\n",
    "    \n",
    "    utterance = utterance_match.group(1).strip() if utterance_match else None\n",
    "    action_order_str = action_order_match.group(1).strip() if action_order_match else None\n",
    "    \n",
    "    try:\n",
    "        action_order = json.loads(action_order_str.replace(\"'\", '\"'))\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        action_order = None\n",
    "    \n",
    "    return utterance, action_order\n",
    "\n",
    "def generate_utterance_and_action():\n",
    "    # Randomly select elements from the Ableton data\n",
    "    audio_effect = random.choice(audio_effects)\n",
    "    instrument = random.choice(list(device_types.keys()))\n",
    "    device_type = random.choice(device_types[instrument]) if device_types[instrument] else ''\n",
    "\n",
    "    # Select actions and modifiers\n",
    "    track_creation_action = random.choice(actions['track_creation_actions'])\n",
    "    track_action = random.choice(actions['track_actions'])\n",
    "    project_action = random.choice(actions['project_actions'])\n",
    "    clip_action = random.choice(actions['clip_actions'])\n",
    "    value_action = random.choice(actions['value_actions'])\n",
    "    view_action = random.choice(actions['view_actions'])\n",
    "    mapping_action = random.choice(actions['mapping_actions'])\n",
    "    \n",
    "    speed_modifier_category = random.choice(list(actions['speed_modifiers'].keys()))\n",
    "    speed_modifier = random.choice(actions['speed_modifiers'][speed_modifier_category])\n",
    "    \n",
    "    # Randomly select a template\n",
    "    template = random.choice(utterance_templates)\n",
    "    \n",
    "    # Generate random track numbers and other values\n",
    "    track_number = random.randint(1, 8)\n",
    "    track_number1 = random.randint(1, 8)\n",
    "    track_number2 = random.randint(1, 8)\n",
    "    while track_number2 == track_number1:\n",
    "        track_number2 = random.randint(1, 8)\n",
    "    \n",
    "    clip_number = random.randint(1, 16)\n",
    "    value = random.randint(0, 100)\n",
    "    map_number = random.randint(1, 128)\n",
    "    track_type = random.choice(track_types)\n",
    "    device_name = random.choice(audio_effects + list(device_types.keys()))\n",
    "    parameter = random.choice(parameters)\n",
    "    \n",
    "    # Create placeholders dictionary\n",
    "    placeholders = {\n",
    "        'track_number': track_number,\n",
    "        'track_number1': track_number1,\n",
    "        'track_number2': track_number2,\n",
    "        'clip_number': clip_number,\n",
    "        'value': value,\n",
    "        'number': map_number,\n",
    "        'audio_effect': audio_effect,\n",
    "        'instrument': instrument,\n",
    "        'device_type': device_type,\n",
    "        'track_creation_action': track_creation_action,\n",
    "        'track_action': track_action,\n",
    "        'project_action': project_action,\n",
    "        'clip_action': clip_action,\n",
    "        'value_action': value_action,\n",
    "        'view_action': view_action,\n",
    "        'mapping_action': mapping_action,\n",
    "        'speed_modifier': speed_modifier,\n",
    "        'track_type': track_type,\n",
    "        'device_name': device_name,\n",
    "        'parameter': parameter\n",
    "    }\n",
    "    \n",
    "    # Format placeholders\n",
    "    placeholders_str = format_placeholders(placeholders)\n",
    "    \n",
    "    # Prepare examples\n",
    "    examples = format_examples(examples_list)\n",
    "    \n",
    "    # Prepare the prompt\n",
    "    prompt = prompt_template.format(placeholders=placeholders_str, examples=examples)\n",
    "    \n",
    "    # Invoke the LLM\n",
    "    output = llm(prompt)\n",
    "    \n",
    "    # Extract the utterance and action order\n",
    "    utterance, action_order = extract_utterance_and_action(output)\n",
    "    \n",
    "    if not utterance or not action_order:\n",
    "        logger.warning(f\"Failed to extract utterance or action order from output: {output}\")\n",
    "        return None, None\n",
    "    \n",
    "    return utterance, action_order\n",
    "\n",
    "# Generate the data\n",
    "num_generations = 100  # Adjust as needed\n",
    "generated_data = []\n",
    "\n",
    "for _ in tqdm(range(num_generations), desc=\"Generating utterances and actions\"):\n",
    "    utterance, action_order = generate_utterance_and_action()\n",
    "    if utterance and action_order:\n",
    "        generated_data.append({\"Utterance\": utterance, \"Action_Order\": action_order})\n",
    "\n",
    "print(f\"Generated {len(generated_data)} utterances and action orders.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Enable tqdm for pandas operations\n",
    "tqdm.pandas()\n",
    "\n",
    "def create_csv_from_ai_output(input_data, output_file):\n",
    "    # Convert the input data to a pandas DataFrame\n",
    "    df = pd.DataFrame(input_data)\n",
    "    \n",
    "    # Convert the Action_Order list to a comma-separated string\n",
    "    df['Action_Order'] = df['Action_Order'].progress_apply(lambda x: ', '.join(x))\n",
    "    \n",
    "    # Write the DataFrame to a CSV file\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"CSV file '{output_file}' has been created successfully.\")\n",
    "\n",
    "# Create the CSV file\n",
    "output_file = 'ableton_utterances_and_actions.csv'\n",
    "create_csv_from_ai_output(generated_data, output_file)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
