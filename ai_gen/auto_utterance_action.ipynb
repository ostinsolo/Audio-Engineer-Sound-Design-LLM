{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Check if running in Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Colab-specific setup\n",
    "    !pip install langchain langchain_ollama pandas tqdm\n",
    "    !git clone https://github.com/ostinsolo/Audio-Engineer-Sound-Design-LLM.git\n",
    "    %cd Audio-Engineer-Sound-Design-LLM/ai_gen\n",
    "else:\n",
    "    # Local system setup\n",
    "    # Check if we're in the correct directory, if not, change to it\n",
    "    if not os.path.exists('ableton_data.py'):\n",
    "        os.chdir('/Users/ostinsolo/Documents/Code/Audio-Engineer-Sound-Design-LLM/ai_gen')\n",
    "    \n",
    "    # Create and activate a virtual environment named 'aigen'\n",
    "    !python -m venv aigen\n",
    "    if sys.platform == \"win32\":\n",
    "        !aigen\\Scripts\\activate\n",
    "    else:\n",
    "        !source aigen/bin/activate\n",
    "    \n",
    "    # Install required packages in the virtual environment\n",
    "    !pip install langchain langchain_ollama pandas tqdm\n",
    "\n",
    "# Add the current directory to Python's path\n",
    "sys.path.append('.')\n",
    "\n",
    "# Load the Ableton data\n",
    "from ableton_data import *\n",
    "\n",
    "# Load the Ollama LLM\n",
    "llm = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"ableton_data\"],\n",
    "    template=\"\"\"\n",
    "Generate a unique utterance for an Ableton Live task and its corresponding action order. Use the provided Ableton data to ensure relevance and accuracy.\n",
    "\n",
    "Ableton Data:\n",
    "{ableton_data}\n",
    "\n",
    "Format the output as follows:\n",
    "Utterance: [insert utterance here]\n",
    "Action Order: [\"step 1\", \"step 2\", ...]\n",
    "\n",
    "Rules:\n",
    "1. Track creation actions don't include a track number (the track doesn't exist yet).\n",
    "2. Other track-related actions always start with \"track {ableton_data[track_number]}\".\n",
    "3. Device-related actions always start with \"track {ableton_data[track_number]}\", \"search device\", followed by the device name.\n",
    "4. For instruments, the order is: \"track {ableton_data[track_number]}\", \"search device\", \"{ableton_data[instrument]}\", \"{ableton_data[device_type]}\".\n",
    "5. Audio effects are treated separately from instruments.\n",
    "6. Value actions include the device name, parameter, action (set/increase/decrease), speed modifier, and value.\n",
    "7. Project actions are global and don't require a track number.\n",
    "8. Clip actions always include a track number and clip number.\n",
    "9. View actions change the current view in Ableton Live and don't require a track number.\n",
    "10. Mapping actions involve assigning controls to parameters and may not require a track number.\n",
    "\n",
    "Placeholder Usage:\n",
    "- Use {ableton_data[track_creation_actions]} for creating new tracks.\n",
    "- Use {ableton_data[track_actions]} for actions on specific tracks.\n",
    "- Use {ableton_data[audio_effect]} for audio effects.\n",
    "- Use {ableton_data[instrument]} and {ableton_data[device_type]} for instruments.\n",
    "- Use {ableton_data[project_actions]} for global project actions.\n",
    "- Use {ableton_data[track_type]} when specifying track types.\n",
    "- Use {ableton_data[clip_actions]} for actions on clips.\n",
    "- Use {ableton_data[device_name]} and {ableton_data[parameter]} when adjusting devices.\n",
    "- Use {ableton_data[value_actions]} and {ableton_data[speed_modifiers]} for value changes.\n",
    "- Use {ableton_data[view_actions]} for changing views in Ableton Live.\n",
    "- Use {ableton_data[mapping_actions]} for control mapping operations.\n",
    "\n",
    "Action Types:\n",
    "1. Track creation actions: Create new tracks without a track number.\n",
    "2. Track actions: Perform on specific tracks, require a track number.\n",
    "3. Project actions: Global actions, no track number required.\n",
    "4. Device actions: Perform on devices within tracks, require track number and device name.\n",
    "5. Clip actions: Perform on clips within tracks, require track number and clip number.\n",
    "6. Value actions: Modify device parameters, require track number, device name, parameter, action, speed modifier, and value.\n",
    "7. View actions: Change the current view, no track number required.\n",
    "8. Mapping actions: Assign controls to parameters, may or may not require a track number.\n",
    "\n",
    "Now generate a new, unique utterance and action order:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "def extract_utterance_and_action(response):\n",
    "    utterance_match = re.search(r'Utterance: (.+)', response)\n",
    "    action_order_match = re.search(r'Action Order: (\\[.+\\])', response)\n",
    "    \n",
    "    utterance = utterance_match.group(1) if utterance_match else None\n",
    "    action_order = eval(action_order_match.group(1)) if action_order_match else None\n",
    "    \n",
    "    return utterance, action_order\n",
    "\n",
    "def generate_utterance_and_action():\n",
    "    # Randomly select elements from the Ableton data to encourage variety\n",
    "    audio_effect = random.choice(audio_effects)\n",
    "    instrument = random.choice(list(device_types.keys()))\n",
    "    device_type = random.choice(device_types[instrument])\n",
    "    \n",
    "    # Correctly handle actions and speed modifiers\n",
    "    track_creation_action = random.choice(actions['track_creation_actions'])\n",
    "    track_action = random.choice(actions['track_actions'])\n",
    "    project_action = random.choice(actions['project_actions'])\n",
    "    clip_action = random.choice(actions['clip_actions'])\n",
    "    value_action = random.choice(actions['value_actions'])\n",
    "    view_action = random.choice(actions['view_actions'])\n",
    "    mapping_action = random.choice(actions['mapping_actions'])\n",
    "    \n",
    "    speed_modifier_category = random.choice(list(actions['speed_modifiers'].keys()))\n",
    "    speed_modifier = random.choice(actions['speed_modifiers'][speed_modifier_category])\n",
    "    \n",
    "    template = random.choice(utterance_templates)\n",
    "    \n",
    "    # Generate random track numbers\n",
    "    track_number = random.randint(1, 8)\n",
    "    track_number1 = random.randint(1, 8)\n",
    "    track_number2 = random.randint(1, 8)\n",
    "    while track_number2 == track_number1:\n",
    "        track_number2 = random.randint(1, 8)\n",
    "    \n",
    "    # Generate other random values\n",
    "    clip_number = random.randint(1, 16)\n",
    "    value = random.randint(0, 100)\n",
    "    map_number = random.randint(1, 128)\n",
    "    \n",
    "    # Create a simplified version of the Ableton data to pass to the AI\n",
    "    simplified_data = {\n",
    "        'track_number': track_number,\n",
    "        'track_number1': track_number1,\n",
    "        'track_number2': track_number2,\n",
    "        'clip_number': clip_number,\n",
    "        'value': value,\n",
    "        'number': map_number,\n",
    "        'audio_effect': audio_effect,\n",
    "        'instrument': instrument,\n",
    "        'device_type': device_type,\n",
    "        'track_creation_actions': track_creation_action,\n",
    "        'track_actions': track_action,\n",
    "        'project_actions': project_action,\n",
    "        'clip_actions': clip_action,\n",
    "        'value_actions': value_action,\n",
    "        'view_actions': view_action,\n",
    "        'mapping_actions': mapping_action,\n",
    "        'speed_modifiers': speed_modifier,\n",
    "        'track_type': random.choice(track_types),\n",
    "        'device_name': random.choice(audio_effects + list(device_types.keys())),\n",
    "        'parameter': random.choice(parameters)\n",
    "    }\n",
    "    \n",
    "    # Format the template with the simplified data\n",
    "    try:\n",
    "        formatted_template = template.format(**simplified_data)\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {e} is missing in the simplified_data\")\n",
    "        print(\"Template:\", template)\n",
    "        print(\"Simplified data:\", simplified_data)\n",
    "        return None, None\n",
    "    \n",
    "    # Pass the simplified_data to the prompt_template, not the formatted_template\n",
    "    prompt = prompt_template.format(ableton_data=simplified_data)\n",
    "    output = llm(prompt)\n",
    "    return extract_utterance_and_action(output)\n",
    "\n",
    "# Generate the data\n",
    "num_generations = 100  # You can adjust this number\n",
    "generated_data = []\n",
    "\n",
    "for _ in tqdm(range(num_generations), desc=\"Generating utterances and actions\"):\n",
    "    utterance, action_order = generate_utterance_and_action()\n",
    "    if utterance and action_order:\n",
    "        generated_data.append({\"Utterance\": utterance, \"Action_Order\": action_order})\n",
    "\n",
    "print(f\"Generated {len(generated_data)} utterances and action orders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Enable tqdm for pandas operations\n",
    "tqdm.pandas()\n",
    "\n",
    "def create_csv_from_ai_output(input_data, output_file):\n",
    "    # Convert the input data to a pandas DataFrame\n",
    "    df = pd.DataFrame(input_data)\n",
    "    \n",
    "    # Convert the Action_Order list to a comma-separated string\n",
    "    df['Action_Order'] = df['Action_Order'].progress_apply(lambda x: ', '.join(x))\n",
    "    \n",
    "    # Write the DataFrame to a CSV file\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"CSV file '{output_file}' has been created successfully.\")\n",
    "\n",
    "# Create the CSV file\n",
    "output_file = 'ableton_utterances_and_actions.csv'\n",
    "create_csv_from_ai_output(generated_data, output_file)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
